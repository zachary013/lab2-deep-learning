# Lab 2: Computer Vision with PyTorch ğŸ–¼ï¸

![Computer Vision](https://img.shields.io/badge/Computer%20Vision-CNN%20%26%20Transformers-blue?style=for-the-badge&logo=python)  
![Status](https://img.shields.io/badge/Status-Completed-brightgreen?style=for-the-badge)  
![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge&logo=opensource)  
![PyTorch](https://img.shields.io/badge/PyTorch-v2.0.1-orange?style=for-the-badge&logo=pytorch)

## ğŸ”¥ Project Overview
Welcome to **Lab 2: Computer Vision with PyTorch**, my submission for the Deep Learning course at Abdelmalek Essaadi University! This project dives into MNIST digit classification using a lineup of powerful models:
- **CNN**: A custom convolutional neural network for fast and effective classification.
- **Faster R-CNN**: Adapted for classification, showing off object detection capabilities.
- **VGG16 & AlexNet**: Pretrained giants fine-tuned for MNIST.
- **Vision Transformer (ViT)**: A from-scratch transformer to flex modern architectures.

Built with **PyTorch** on Google Colabâ€™s T4 GPU, this repo packs a punch with model building, fine-tuning, and metric comparisonsâ€”all in a single Jupyter Notebook.

---

## ğŸ› ï¸ Features
- ğŸ–¼ï¸ **MNIST Classification**: Tackles digit recognition with 5 models (CNN, Faster R-CNN, VGG16, AlexNet, ViT).
- ğŸ“Š **Metrics Galore**: Accuracy, F1 score, loss, and training time for all models.
- âš¡ **GPU Power**: Leverages Colabâ€™s T4 GPU for speedy training.
- ğŸ”§ **Fine-Tuning**: Pretrained VGG16 and AlexNet adjusted for MNIST (1-channel, 10 classes).
- ğŸ§  **From Scratch**: ViT built from the ground upâ€”patches, transformers, and all!

---

## ğŸ“‹ Table of Contents
- [Requirements](#-requirements)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Results](#-results)
- [Prepared by](#prepared-by)
- [Contributing](#-contributing)
- [License](#-license)
- [Shoutouts](#-shoutouts)

---

## ğŸ“¦ Requirements
To run this project, you'll need:
- **Python 3.8+**
- **Jupyter Notebook** (or Colab)
- **Dependencies**:
  ```plaintext
  torch==2.0.1
  torchvision==0.15.2
  pandas==2.0.3
  numpy==1.24.3
  scikit-learn==1.3.0
  kagglehub
  ```
Optional: GPU with CUDA for faster training.

## âš™ï¸ Installation
Clone the Repo:
```bash
git clone https://github.com/zachary013/lab2-computer-vision.git
cd lab2-computer-vision
```

Set Up a Virtual Env:
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

Install the Goods:
```bash
pip install -r requirements.txt
```
No requirements.txt yet? Copy the list above and run pip install <package> for each.

Launch Jupyter:
```bash
jupyter notebook
```

## ğŸš€ Usage
Open the Notebook:
Fire up lab2_computer_vision.ipynb in Jupyter or upload it to Google Colab.

Run It:
Hit Run All (or Shift + Enter cell-by-cell) to:
- Download the MNIST dataset via torchvision.
- Train and evaluate all 5 models.
- Print metrics (accuracy, F1, loss, time).

Outputs:
Check inline results for each model's performance.

Pro Tip: Use Colab's free T4 GPU for faster trainingâ€”set it up in Runtime > Change runtime type!

## ğŸ“‚ Project Structure
```text
lab2-computer-vision/
â”œâ”€â”€ lab2_computer_vision.ipynb  # The main notebook: code and results
â”œâ”€â”€ lab2_report.pdf             # LaTeX report with detailed analysis
â”œâ”€â”€ requirements.txt            # Dependency list (create it if missing)
â””â”€â”€ README.md                   # This guide
```
MNIST dataset is fetched dynamically via torchvisionâ€”no local storage needed!

## ğŸ¯ Results
### Model Performance
All models were trained on MNIST (60,000 train, 10,000 test images) using Colab's T4 GPU. Here's how they stacked up:

**CNN**:
- Accuracy: 98.76%
- F1 Score: 0.9876
- Loss: 0.0412
- Time: 45.32s

**Faster R-CNN**:
- Accuracy: 97.83%
- F1 Score: 0.9781
- Loss: 0.0698
- Time: 112.45s

**VGG16**:
- Accuracy: 99.21%
- F1 Score: 0.9920
- Loss: 0.0289
- Time: 187.63s

**AlexNet**:
- Accuracy: 98.94%
- F1 Score: 0.9893
- Loss: 0.0376
- Time: 156.19s

**ViT**:
- Accuracy: 98.52%
- F1 Score: 0.9851
- Loss: 0.0482
- Time: 203.76s

### Key Takeaways
- Pretrained models (VGG16, AlexNet) led the pack, thanks to transfer learning.
- CNN was the fastest and still scored highâ€”great for simple tasks like MNIST.
- ViT showed transformer potential but took longer to train.
- Faster R-CNN lagged; it's overkill for basic classification.

## Prepared by
| Avatar | Name | GitHub |
|--------|------|--------|
| <img src="https://github.com/zachary013.png" width="50" height="50" style="border-radius: 50%"/> | Zakariae Azarkan | @zachary013 |

## ğŸ¤ Contributing
This is my uni work, so I'm not accepting pull requestsâ€”but feel free to fork and experiment! Got ideas? Drop them in GitHub Issues.

## ğŸ“œ License
Licensed under the MIT Licenseâ€”use it, share it, just don't blame me if your GPU overheats! ğŸ”¥

## ğŸ™Œ Shoutouts
- Prof. Lotfi EL AACHAK for guiding this lab.
- PyTorch team for an awesome framework.
- Colab for free GPU accessâ€”lifesaver!
- MNIST Dataset for being the perfect playground for vision tasks.
